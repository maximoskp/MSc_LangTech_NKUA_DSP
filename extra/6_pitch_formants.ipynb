{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim of this class\n",
    "In this class we will employ formants for classifying vowels for a specific speaker. To this end, you will first need to:\n",
    "\n",
    "1) Record different vowels in four different pitch heights each (e.g. 'a', 'o' and 'ee').\n",
    "\n",
    "2) pip install conch_sounds\n",
    "\n",
    "3) The above mentioned library can be found here: https://github.com/mmcauliffe/Conch-sounds\n",
    "\n",
    "#### Caution: to make the aforementioned library work, you need to make a code change according to this issue:\n",
    "https://github.com/mmcauliffe/Conch-sounds/issues/12\n",
    "\n",
    "The following cells include functions and processes for extracting formants among other features from recordings of vowels. These features are stored in structures which are subsequently used for generating graphs and for having a first look at Principal Component Analysis.\n",
    "\n",
    "### Praat vs Python\n",
    "Praat offers intuitive interaction with recordings, which is extremely useful for thorough investigation of specific short recorded segments. Python does not include the interaction layer, but it allows the development of specialised algorithms for analysing multiple recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conch.analysis.formants import FormantTrackFunction\n",
    "from conch.analysis.pitch import PitchTrackFunction\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# define a function for extracting the desired features and for storing them in proper structures for further processing\n",
    "\n",
    "def get_pitch_and_formants(f):\n",
    "    func = PitchTrackFunction(time_step=0.01, min_pitch=75, max_pitch=600)\n",
    "    pitch = func(f)\n",
    "    func = FormantTrackFunction(time_step=0.01,\n",
    "                                window_length=0.025, num_formants=5, max_frequency=5500)\n",
    "    formants = func(f)\n",
    "    # sync\n",
    "    kp = np.array( list( pitch.keys() ) )\n",
    "    kf = np.array( list( formants.keys() ) )\n",
    "    \n",
    "    synced = {}\n",
    "    for t in kp:\n",
    "        # find nearest value in formants\n",
    "        idx = (np.abs( kf - t )).argmin()\n",
    "        formants_freqs_list = []\n",
    "        formants_ratios_list = []\n",
    "        formants_amps_list = []\n",
    "        current_pitch = pitch[ t ]\n",
    "        if current_pitch[0] != 0:\n",
    "            for fmnt in formants[ kf[ idx ] ]:\n",
    "                if current_pitch[0] is not None and fmnt[0] is not None:\n",
    "                    formants_freqs_list.append( fmnt[0] )\n",
    "                    formants_amps_list.append( fmnt[1] )\n",
    "                    formants_ratios_list.append( fmnt[0]/current_pitch[0] )\n",
    "            synced[ t ] = {\n",
    "                'pitch': pitch[ t ],\n",
    "                'time': t,\n",
    "                'formants_freqs': formants_freqs_list,\n",
    "                'formants_amps': formants_amps_list,\n",
    "                'formants_ratios': formants_ratios_list,\n",
    "            }\n",
    "    \n",
    "    return synced, pitch, formants, kp, kf\n",
    "# end get_pitch_and_formants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "resample() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m gt_pitch_formants \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     sa, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_pitch_and_formants\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../audio_files/ah/ah_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     ah_pitch_formants\u001b[38;5;241m.\u001b[39mappend( sa )\n\u001b[0;32m      9\u001b[0m     so, _, _, _, _ \u001b[38;5;241m=\u001b[39m get_pitch_and_formants( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../audio_files/oh/oh_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m, in \u001b[0;36mget_pitch_and_formants\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m     10\u001b[0m pitch \u001b[38;5;241m=\u001b[39m func(f)\n\u001b[0;32m     11\u001b[0m func \u001b[38;5;241m=\u001b[39m FormantTrackFunction(time_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     12\u001b[0m                             window_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.025\u001b[39m, num_formants\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, max_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5500\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m formants \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# sync\u001b[39;00m\n\u001b[0;32m     15\u001b[0m kp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray( \u001b[38;5;28mlist\u001b[39m( pitch\u001b[38;5;241m.\u001b[39mkeys() ) )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\audio_courses\\lib\\site-packages\\conch\\analysis\\functions.py:42\u001b[0m, in \u001b[0;36mBaseAnalysisFunction.__call__\u001b[1;34m(self, segment)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(segment, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_file:\n\u001b[0;32m     41\u001b[0m     signal, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(safe_path(segment))\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(segment, FileSegment) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_segment_as_arg:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function(segment, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marguments)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\audio_courses\\lib\\site-packages\\conch\\analysis\\formants\\lpc.py:219\u001b[0m, in \u001b[0;36mlpc_formants\u001b[1;34m(signal, sr, num_formants, max_freq, time_step, win_len, window_shape)\u001b[0m\n\u001b[0;32m    217\u001b[0m proc \u001b[38;5;241m=\u001b[39m lfilter([\u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m-\u001b[39malpha], \u001b[38;5;241m1\u001b[39m, signal)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;241m>\u001b[39m new_sr:\n\u001b[1;32m--> 219\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_sr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m nperseg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(win_len \u001b[38;5;241m*\u001b[39m new_sr)\n\u001b[0;32m    221\u001b[0m nperstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(time_step \u001b[38;5;241m*\u001b[39m new_sr)\n",
      "\u001b[1;31mTypeError\u001b[0m: resample() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "# run for audio files\n",
    "ah_pitch_formants = []\n",
    "oh_pitch_formants = []\n",
    "eeh_pitch_formants = []\n",
    "gt_pitch_formants = []\n",
    "for i in range(4):\n",
    "    sa, _, _, _, _ = get_pitch_and_formants( '../audio_files/ah/ah_' + str(i) + '.wav' )\n",
    "    ah_pitch_formants.append( sa )\n",
    "    so, _, _, _, _ = get_pitch_and_formants( '../audio_files/oh/oh_' + str(i) + '.wav' )\n",
    "    oh_pitch_formants.append( so )\n",
    "    see, _, _, _, _ = get_pitch_and_formants( '../audio_files/eeh/eeh_' + str(i) + '.wav' )\n",
    "    eeh_pitch_formants.append( see )\n",
    "    gt, _, _, _, _ = get_pitch_and_formants( '../audio_files/gt/gt_' + str(i) + '.wav' )\n",
    "    gt_pitch_formants.append( gt )\n",
    "\n",
    "# sachirp, _, _, tachirp, _ = get_pitch_and_formants( 'audio_files/ah/ah_chirp.wav' )\n",
    "# sochirp, _, _, tochirp, _ = get_pitch_and_formants( 'audio_files/oh/oh_chirp.wav' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define a function for ploting structures\n",
    "\n",
    "def compount_pitch_formants_plot(file_name, pitch_formants, plt_alias, idx):\n",
    "    y, sr = librosa.load(file_name, sr=44100)\n",
    "    n_fft = 8096\n",
    "    hop_size = 256\n",
    "    p = librosa.stft(y, n_fft=n_fft, hop_length=hop_size)\n",
    "    d = librosa.amplitude_to_db( np.abs(p), ref=np.max )\n",
    "    librosa.display.specshow(d, cmap='gray_r', sr=sr, hop_length=hop_size, x_axis='time', y_axis='linear', ax=plt_alias)\n",
    "    # and also, if we restrict to speech-relevant frequencies\n",
    "    lowest_freq = 30\n",
    "    highest_freq = 5000\n",
    "    # plt_alias.ylim([lowest_freq, highest_freq])\n",
    "    plt_alias.set_ylim([lowest_freq, highest_freq])\n",
    "\n",
    "    # append pitch\n",
    "    p = []\n",
    "    t = []\n",
    "    fmnts = []\n",
    "    for k in list( pitch_formants.keys() ):\n",
    "        a = pitch_formants[k]\n",
    "        p.append( a['pitch'] )\n",
    "        t.append( a['time'] )\n",
    "        fmnts.append( a['formants_freqs'] )\n",
    "\n",
    "    p = np.array( p )\n",
    "    t = np.array( t )\n",
    "    plt_alias.plot( t , p , 'r.' )\n",
    "    for i in range( t.size ):\n",
    "        for j in range( len(fmnts[i]) ):\n",
    "            plt_alias.plot( t[i] , fmnts[i][j] , 'b.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots are better examined in Praat, which offers valuable interaction possibilities. Ploting in Python offers a first intuitive approach on what differences we should expect from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,a =  plt.subplots(2,2)\n",
    "\n",
    "for i in range( 4 ):\n",
    "    file_name = '../audio_files/ah/ah_' + str(i) + '.wav'\n",
    "    pitch_formants = ah_pitch_formants[i]\n",
    "    compount_pitch_formants_plot(file_name, pitch_formants, a[i//2][i%2], i)\n",
    "\n",
    "fig.savefig('../figs/ahs.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,a =  plt.subplots(2,2)\n",
    "\n",
    "for i in range( 4 ):\n",
    "    file_name = '../audio_files/oh/oh_' + str(i) + '.wav'\n",
    "    pitch_formants = oh_pitch_formants[i]\n",
    "    compount_pitch_formants_plot(file_name, pitch_formants, a[i//2][i%2], i)\n",
    "\n",
    "fig.savefig('../figs/ohs.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,a =  plt.subplots(2,2)\n",
    "\n",
    "for i in range( 4 ):\n",
    "    file_name = '../audio_files/eeh/eeh_' + str(i) + '.wav'\n",
    "    pitch_formants = eeh_pitch_formants[i]\n",
    "    compount_pitch_formants_plot(file_name, pitch_formants, a[i//2][i%2], i)\n",
    "\n",
    "fig.savefig('../figs/eehs.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,a =  plt.subplots(2,2)\n",
    "\n",
    "for i in range( 4 ):\n",
    "    file_name = '../audio_files/gt/gt_' + str(i) + '.wav'\n",
    "    pitch_formants = gt_pitch_formants[i]\n",
    "    compount_pitch_formants_plot(file_name, pitch_formants, a[i//2][i%2], i)\n",
    "\n",
    "fig.savefig('../figs/gt.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for forming a matrix that incorporates 5-tuples of formants\n",
    "# for each frame and for every recording of a vowel\n",
    "def isolate_5_formant_stats(s):\n",
    "    fmnts = np.zeros( ( len(s) , 5 ) )\n",
    "    nnz = 0\n",
    "    for i , k in enumerate( list( s.keys() ) ):\n",
    "        a = s[k]\n",
    "        tmp_arr = np.array(a['formants_freqs'])\n",
    "        if tmp_arr.size == 5 and 0 not in tmp_arr:\n",
    "            fmnts[i, :] = tmp_arr\n",
    "            nnz += 1\n",
    "    ret_fmnts = np.zeros( ( nnz , 5 ) )\n",
    "    nnz = 0\n",
    "    for i in range( fmnts.shape[0] ):\n",
    "        if np.sum( fmnts[i,:] ) > 0:\n",
    "            ret_fmnts[nnz, :] = fmnts[i,:]\n",
    "            nnz += 1\n",
    "    return ret_fmnts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function defined above, all the identified formants are isolated (stacked) for every recording of each vowel. For example, the first cell includes the formants identified for all recordings of 'a'.\n",
    "\n",
    "Each vowel is then ploted with boxplots. Each box corresponds to the distribution of the respective formant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah_stacked = isolate_5_formant_stats( ah_pitch_formants[0] )\n",
    "for i in range( 1, 4, 1 ):\n",
    "    ah_stacked = np.vstack( ( ah_stacked , isolate_5_formant_stats( ah_pitch_formants[i] ) ) )\n",
    "\n",
    "_ = plt.boxplot( ah_stacked )\n",
    "plt.savefig('../figs/ah_boxplot.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_stacked = isolate_5_formant_stats( oh_pitch_formants[0] )\n",
    "for i in range( 1, 4, 1 ):\n",
    "    oh_stacked = np.vstack( ( oh_stacked , isolate_5_formant_stats( oh_pitch_formants[i] ) ) )\n",
    "\n",
    "_ = plt.boxplot( oh_stacked )\n",
    "plt.savefig('../figs/oh_boxplot.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeh_stacked = isolate_5_formant_stats( eeh_pitch_formants[0] )\n",
    "for i in range( 1, 4, 1 ):\n",
    "    eeh_stacked = np.vstack( ( eeh_stacked , isolate_5_formant_stats( eeh_pitch_formants[i] ) ) )\n",
    "\n",
    "_ = plt.boxplot( eeh_stacked )\n",
    "plt.savefig('../figs/eeh_boxplot.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A boxplot of all formants of all vowels reveals that there are significant differences in the formants layout. For example, F1 and F2 are distinctive for all vowel recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined plot\n",
    "idx = np.min( np.array( [ah_stacked.shape[0] , oh_stacked.shape[0] , eeh_stacked.shape[0] ] ) )\n",
    "comp = np.hstack( ( ah_stacked[:idx,:] , oh_stacked[:idx,:] , eeh_stacked[:idx,:] ) )\n",
    "\n",
    "_ = plt.boxplot( comp )\n",
    "plt.savefig('../figs/comp_boxplot.png', dpi=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the first two formants (F1 on x and F2 on y) shows that F2, in its own right, is enough for linearly separating the vowel recordings (i.e. by drawing horizontal lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [ 'a' , 'o' , 'i' ]\n",
    "colors = [ 'r' , 'g' , 'b' ]\n",
    "compv = np.vstack( ( ah_stacked[:idx,:] , oh_stacked[:idx,:] , eeh_stacked[:idx,:] ) )\n",
    "idxs = np.hstack( ( 0*np.ones( idx ) , 1*np.ones( idx ) , 2*np.ones( idx ) ) ).astype(int)\n",
    "\n",
    "fig,a =  plt.subplots()\n",
    "\n",
    "for i in range( compv.shape[0] ):\n",
    "    a.plot( compv[i,0] , compv[i,1] , '.', color=colors[idxs[i]] )\n",
    "    a.annotate( letters[ idxs[i] ] , (compv[i,0] , compv[i,1]) , color = colors[ idxs[i] ] )\n",
    "\n",
    "fig.show()\n",
    "fig.savefig( '../figs/comp_2d.png' , dpi=500 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we get even better discrimination? Yes, by applying Principal Component Analysis (PCA). PCA brings into play all the formants, which reveal additional aspects and subgroups within each vowel space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(compv)\n",
    "transformed = pca.transform(compv)\n",
    "\n",
    "fig,a =  plt.subplots()\n",
    "\n",
    "for i in range( compv.shape[0] ):\n",
    "    a.plot( transformed[i,0] , transformed[i,1] , '.', color=colors[idxs[i]] )\n",
    "    a.annotate( letters[ idxs[i] ] , (transformed[i,0] , transformed[i,1]) , color = colors[ idxs[i] ] )\n",
    "\n",
    "fig.show()\n",
    "fig.savefig( '../figs/comp_PCA.png' , dpi=500 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
